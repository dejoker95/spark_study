{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12장 RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-21-235.ec2.internal:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.6</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PySparkShell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=PySparkShell>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[5] at javaToPython at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.range(10).rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[12] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.range(10).toDF('id').rdd.map(lambda row: row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.range(10).rdd.toDF()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.3.2 로컬 컬렉션으로 RDD 생성하기\n",
    "\n",
    "### 두 개의 파티션을 가진 병렬 컬렉션 객체 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCollection = \"Spark The Definitive Guide : Big Data Processing Made Simple\".split(' ')\n",
    "\n",
    "words = spark.sparkContext.parallelize(myCollection, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'myWords'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.setName('myWords')\n",
    "words.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myWords ParallelCollectionRDD[24] at parallelize at PythonRDD.scala:195"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.5 트랜스포메이션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.5.1 distinct\n",
    "words.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[30] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.5.2 filter\n",
    "def startsWithS(individual):\n",
    "    return individual.startswith('S')\n",
    "\n",
    "words.filter(lambda word: startsWithS(word).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spark', 'S', True), ('Simple', 'S', True)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.5.3 map\n",
    "words2 = words.map(lambda word: (word, word[0], word.startswith('S')))\n",
    "words2.filter(lambda record: record[2]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spark', 'S', True),\n",
       " ('The', 'T', False),\n",
       " ('Definitive', 'D', False),\n",
       " ('Guide', 'G', False),\n",
       " (':', ':', False)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words2.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S', 'p', 'a', 'r', 'k']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## flat map\n",
    "words.flatMap(lambda word: list(word)).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Definitive',\n",
       " 'Processing',\n",
       " 'Simple',\n",
       " 'Spark',\n",
       " 'Guide',\n",
       " 'Data',\n",
       " 'Made',\n",
       " 'The',\n",
       " 'Big',\n",
       " ':']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.5.4 sortBy\n",
    "words.sortBy(lambda word: len(word) * -1).take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark', 'Definitive', 'Data', 'Processing', 'Made']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.5.5 randomSplit\n",
    "fiftyFiftySplit = words.randomSplit([0.5, 0.5])\n",
    "fiftyFiftySplit[0].take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Guide', ':', 'Big', 'Simple']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fiftyFiftySplit[1].take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12.6 액션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.6.1 reduce\n",
    "spark.sparkContext.parallelize(range(1, 21)).reduce(lambda x, y: x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Processing'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def wordLengthReducer(leftWord, rightWord):\n",
    "    if len(leftWord) > len(rightWord):\n",
    "        return leftWord\n",
    "    else:\n",
    "        return rightWord\n",
    "    \n",
    "words.reduce(wordLengthReducer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.6.2 count\n",
    "words.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## countApprox\n",
    "confidence = 0.95\n",
    "timeoutMilliseconds = 400\n",
    "words.countApprox(timeoutMilliseconds, confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## countApproxDistinct\n",
    "words.countApproxDistinct(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'Spark': 1,\n",
       "             'The': 1,\n",
       "             'Definitive': 1,\n",
       "             'Guide': 1,\n",
       "             ':': 1,\n",
       "             'Big': 1,\n",
       "             'Data': 1,\n",
       "             'Processing': 1,\n",
       "             'Made': 1,\n",
       "             'Simple': 1})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## countByValue\n",
    "words.countByValue()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spark'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.6.3 first\n",
    "words.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.6.4 max, min\n",
    "spark.sparkContext.parallelize(range(1, 21)).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sparkContext.parallelize(range(1, 21)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark', 'The', 'Definitive', 'Guide', ':']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.6.5 take\n",
    "words.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[':', 'Big', 'Data', 'Definitive', 'Guide']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.takeOrdered(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'Spark', 'Simple', 'Processing', 'Made']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.top(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data', 'Definitive', 'Data', 'The', 'Definitive', 'Spark']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "withReplacement = True\n",
    "numberToTake = 6\n",
    "randomSeed = 100\n",
    "words.takeSample(withReplacement, numberToTake, randomSeed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.7 파일 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 12.7.1 saveAsTextFile\n",
    "words.saveAsTextFile('file:///home/ubuntu/book')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.8 캐싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "myWords ParallelCollectionRDD[24] at parallelize at PythonRDD.scala:195"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StorageLevel(False, True, False, False, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.getStorageLevel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.9 체크포인팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sparkContext.setCheckpointDir(\"file:///home/ubuntu/checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.checkpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.10 RDD를 시스템 명령을 전송하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '5']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 파티션 당 5개의 로우\n",
    "words.pipe('wc -l').collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.10.1 mapPartitions\n",
    "words.mapPartitions(lambda part: [1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['partition: 0 => Spark',\n",
       " 'partition: 0 => The',\n",
       " 'partition: 0 => Definitive',\n",
       " 'partition: 0 => Guide',\n",
       " 'partition: 0 => :',\n",
       " 'partition: 1 => Big',\n",
       " 'partition: 1 => Data',\n",
       " 'partition: 1 => Processing',\n",
       " 'partition: 1 => Made',\n",
       " 'partition: 1 => Simple']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 파티션 인덱스르 통해 각 레코드가 속한 데이터셋이 어디에 있는지 알아보기\n",
    "def indexedFunc(partitionIndex, withinPartIterator):\n",
    "    return ['partition: {} => {}'.format(partitionIndex, x) for x in withinPartIterator]\n",
    "words.mapPartitionsWithIndex(indexedFunc).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello'], ['World']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.10.3 glom\n",
    "spark.sparkContext.parallelize(['Hello', 'World'], 2).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13 RDD 고급 개념"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCollection = \"Spark The Definitive Guide : Big Data Processing Made Simple\".split(' ')\n",
    "words = spark.sparkContext.parallelize(myCollection, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.1 키-값 형태의 RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "words.map(lambda word : (word.lower(), 1))\n",
    "\n",
    "## 13.1.1 keyBy\n",
    "keyword = words.keyBy(lambda word: word.lower()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 'SPARK'),\n",
       " ('t', 'THE'),\n",
       " ('d', 'DEFINITIVE'),\n",
       " ('g', 'GUIDE'),\n",
       " (':', ':'),\n",
       " ('b', 'BIG'),\n",
       " ('d', 'DATA'),\n",
       " ('p', 'PROCESSING'),\n",
       " ('m', 'MADE'),\n",
       " ('s', 'SIMPLE')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 13.1.2 값 매핑하기\n",
    "keyword.mapValues(lambda word: word.upper()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 'S'),\n",
       " ('s', 'P'),\n",
       " ('s', 'A'),\n",
       " ('s', 'R'),\n",
       " ('s', 'K'),\n",
       " ('t', 'T'),\n",
       " ('t', 'H'),\n",
       " ('t', 'E'),\n",
       " ('d', 'D'),\n",
       " ('d', 'E'),\n",
       " ('d', 'F'),\n",
       " ('d', 'I'),\n",
       " ('d', 'N'),\n",
       " ('d', 'I'),\n",
       " ('d', 'T'),\n",
       " ('d', 'I'),\n",
       " ('d', 'V'),\n",
       " ('d', 'E'),\n",
       " ('g', 'G'),\n",
       " ('g', 'U'),\n",
       " ('g', 'I'),\n",
       " ('g', 'D'),\n",
       " ('g', 'E'),\n",
       " (':', ':'),\n",
       " ('b', 'B'),\n",
       " ('b', 'I'),\n",
       " ('b', 'G'),\n",
       " ('d', 'D'),\n",
       " ('d', 'A'),\n",
       " ('d', 'T'),\n",
       " ('d', 'A'),\n",
       " ('p', 'P'),\n",
       " ('p', 'R'),\n",
       " ('p', 'O'),\n",
       " ('p', 'C'),\n",
       " ('p', 'E'),\n",
       " ('p', 'S'),\n",
       " ('p', 'S'),\n",
       " ('p', 'I'),\n",
       " ('p', 'N'),\n",
       " ('p', 'G'),\n",
       " ('m', 'M'),\n",
       " ('m', 'A'),\n",
       " ('m', 'D'),\n",
       " ('m', 'E'),\n",
       " ('s', 'S'),\n",
       " ('s', 'I'),\n",
       " ('s', 'M'),\n",
       " ('s', 'P'),\n",
       " ('s', 'L'),\n",
       " ('s', 'E')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword.flatMapValues(lambda word: word.upper()).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['s', 't', 'd', 'g', ':', 'b', 'd', 'p', 'm', 's']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 13.1.3 키와 값 추출하기\n",
    "keyword.keys().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark',\n",
       " 'The',\n",
       " 'Definitive',\n",
       " 'Guide',\n",
       " ':',\n",
       " 'Big',\n",
       " 'Data',\n",
       " 'Processing',\n",
       " 'Made',\n",
       " 'Simple']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword.values().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spark', 'Simple']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 12.1.4 lookup\n",
    "keyword.lookup('s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('t', 'The'), ('t', 'The'), ('d', 'Definitive'), ('m', 'Made')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 13.1.5 sampleByKey\n",
    "import random\n",
    "\n",
    "distinctChars = words.flatMap(lambda word: list(word.lower())).distinct().collect()\n",
    "sampleMap = dict(map(lambda c: (c, random.random()), distinctChars))\n",
    "\n",
    "words.map(lambda word: (word.lower()[0], word)).sampleByKey(True, sampleMap, 6).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2 집계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = words.flatMap(lambda word: word.lower())\n",
    "KVcharacters = chars.map(lambda letter: (letter, 1))\n",
    "\n",
    "def maxFunc(left, right):\n",
    "    return max(left, right)\n",
    "def addFunc(left, right):\n",
    "    return left + right\n",
    "nums = sc.parallelize(range(1, 31), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 1), ('p', 1), ('a', 1), ('r', 1), ('k', 1)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'s': 4,\n",
       "             'p': 3,\n",
       "             'a': 4,\n",
       "             'r': 2,\n",
       "             'k': 1,\n",
       "             't': 3,\n",
       "             'h': 1,\n",
       "             'e': 7,\n",
       "             'd': 4,\n",
       "             'f': 1,\n",
       "             'i': 7,\n",
       "             'n': 2,\n",
       "             'v': 1,\n",
       "             'g': 3,\n",
       "             'u': 1,\n",
       "             ':': 1,\n",
       "             'b': 1,\n",
       "             'o': 1,\n",
       "             'c': 1,\n",
       "             'm': 2,\n",
       "             'l': 1})"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## countByKey\n",
    "KVcharacters.countByKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 4),\n",
       " ('p', 3),\n",
       " ('r', 2),\n",
       " ('h', 1),\n",
       " ('d', 4),\n",
       " ('i', 7),\n",
       " ('g', 3),\n",
       " ('b', 1),\n",
       " ('c', 1),\n",
       " ('l', 1),\n",
       " ('a', 4),\n",
       " ('k', 1),\n",
       " ('t', 3),\n",
       " ('e', 7),\n",
       " ('f', 1),\n",
       " ('n', 2),\n",
       " ('v', 1),\n",
       " ('u', 1),\n",
       " (':', 1),\n",
       " ('o', 1),\n",
       " ('m', 2)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## groupByKey\n",
    "from functools import reduce\n",
    "KVcharacters.groupByKey().map(lambda row: (row[0], reduce(addFunc, row[1]))).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 4),\n",
       " ('p', 3),\n",
       " ('r', 2),\n",
       " ('h', 1),\n",
       " ('d', 4),\n",
       " ('i', 7),\n",
       " ('g', 3),\n",
       " ('b', 1),\n",
       " ('c', 1),\n",
       " ('l', 1),\n",
       " ('a', 4),\n",
       " ('k', 1),\n",
       " ('t', 3),\n",
       " ('e', 7),\n",
       " ('f', 1),\n",
       " ('n', 2),\n",
       " ('v', 1),\n",
       " ('u', 1),\n",
       " (':', 1),\n",
       " ('o', 1),\n",
       " ('m', 2)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## reduceByKey\n",
    "KVcharacters.reduceByKey(addFunc).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 13.2.3 기타 집계 메서드\n",
    "## aggregate\n",
    "nums.aggregate(0, maxFunc, addFunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depth = 3\n",
    "nums.treeAggregate(0, maxFunc, addFunc, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nums.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 3),\n",
       " ('p', 2),\n",
       " ('r', 1),\n",
       " ('h', 1),\n",
       " ('d', 2),\n",
       " ('i', 4),\n",
       " ('g', 2),\n",
       " ('b', 1),\n",
       " ('c', 1),\n",
       " ('l', 1),\n",
       " ('a', 3),\n",
       " ('k', 1),\n",
       " ('t', 2),\n",
       " ('e', 4),\n",
       " ('f', 1),\n",
       " ('n', 1),\n",
       " ('v', 1),\n",
       " ('u', 1),\n",
       " (':', 1),\n",
       " ('o', 1),\n",
       " ('m', 2)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## aggregateByKey\n",
    "KVcharacters.aggregateByKey(0, addFunc, maxFunc).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', [1, 1, 1, 1]),\n",
       " ('d', [1, 1, 1, 1]),\n",
       " ('l', [1]),\n",
       " ('v', [1]),\n",
       " (':', [1]),\n",
       " ('p', [1, 1, 1]),\n",
       " ('r', [1, 1]),\n",
       " ('c', [1]),\n",
       " ('k', [1]),\n",
       " ('t', [1, 1, 1]),\n",
       " ('n', [1, 1]),\n",
       " ('u', [1]),\n",
       " ('o', [1]),\n",
       " ('h', [1]),\n",
       " ('i', [1, 1, 1, 1, 1, 1, 1]),\n",
       " ('g', [1, 1, 1]),\n",
       " ('b', [1]),\n",
       " ('a', [1, 1, 1, 1]),\n",
       " ('e', [1, 1, 1, 1, 1, 1, 1]),\n",
       " ('f', [1]),\n",
       " ('m', [1, 1])]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## combineByKey\n",
    "def valToCombiner(value):\n",
    "    return [value]\n",
    "def mergeValuesFunc(vals, valToAppend):\n",
    "    vals.append(valToAppend)\n",
    "    return vals\n",
    "def mergeCombinerFunc(vals1, vals2):\n",
    "    return vals1 + vals2\n",
    "outputPartitions = 6\n",
    "\n",
    "KVcharacters.combineByKey(valToCombiner, mergeValuesFunc, mergeCombinerFunc, outputPartitions).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s', 4),\n",
       " ('p', 3),\n",
       " ('r', 2),\n",
       " ('h', 1),\n",
       " ('d', 4),\n",
       " ('i', 7),\n",
       " ('g', 3),\n",
       " ('b', 1),\n",
       " ('c', 1),\n",
       " ('l', 1),\n",
       " ('a', 4),\n",
       " ('k', 1),\n",
       " ('t', 3),\n",
       " ('e', 7),\n",
       " ('f', 1),\n",
       " ('n', 2),\n",
       " ('v', 1),\n",
       " ('u', 1),\n",
       " (':', 1),\n",
       " ('o', 1),\n",
       " ('m', 2)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## foldByKey 결합 함수와 항등원인 '제로값'을 이용해 각 키의 값을 병함\n",
    "## 제로값은 결과에 여러 번 사용될 수 있으나 결과를 변경할 수 없는 값 (덧셈에서는 0 , 곱셉에서는 1)\n",
    "KVcharacters.foldByKey(0, addFunc).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.3 cogroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('s',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f55c574de90>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f55c4827fd0>)),\n",
       " ('p',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f55c4827e90>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f55c40a8d90>)),\n",
       " ('r',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f55c4803d10>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f55c4803790>)),\n",
       " ('i',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f55c4748190>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f55c40a8f90>)),\n",
       " ('g',\n",
       "  (<pyspark.resultiterable.ResultIterable at 0x7f55c5e20590>,\n",
       "   <pyspark.resultiterable.ResultIterable at 0x7f55c5e203d0>))]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distinctChars = words.flatMap(lambda word: word.lower()).distinct()\n",
    "charRDD = distinctChars.map(lambda c: (c, random.random()))\n",
    "charRDD2 = distinctChars.map(lambda c: (c, random.random()))\n",
    "\n",
    "charRDD.cogroup(charRDD2).take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.4 조인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 13.4.1 내부 조인\n",
    "keyedChars = distinctChars.map(lambda c: (c, random.random()))\n",
    "outputPartitions = 10\n",
    "\n",
    "KVcharacters.join(keyedChars).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KVcharacters.join(keyedChars, outputPartitions).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Spark', 0),\n",
       " ('The', 1),\n",
       " ('Definitive', 2),\n",
       " ('Guide', 3),\n",
       " (':', 4),\n",
       " ('Big', 5),\n",
       " ('Data', 6),\n",
       " ('Processing', 7),\n",
       " ('Made', 8),\n",
       " ('Simple', 9)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 13.4.2 zip\n",
    "numRange = sc.parallelize(range(10), 2)\n",
    "words.zip(numRange).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13.5 파티션 제어하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 13.5.1 coalesce\n",
    "words.coalesce(1).getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[191] at coalesce at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 13.5.2 repartition\n",
    "words.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 13.5.4 사용자 정의 파티셔닝\n",
    "path = \"file:///home/ubuntu/Spark-The-Definitive-Guide-master/data/retail-data/all/online-retail-dataset.csv\"\n",
    "df = spark.read.option(\"header\", 'true').option('inferSchema', 'true').csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- InvoiceNo: string (nullable = true)\n",
      " |-- StockCode: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- InvoiceDate: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      " |-- CustomerID: integer (nullable = true)\n",
      " |-- Country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rdd = df.coalesce(10).rdd\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 4302, 4303]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def partitionFunc(key):\n",
    "    import random\n",
    "    \n",
    "    if key == 17850 or key == 12583:\n",
    "        return 0\n",
    "    else:\n",
    "        return random.randint(1,2)\n",
    "\n",
    "keyedRDD = rdd.keyBy(lambda row: row[6])\n",
    "\n",
    "keyedRDD\\\n",
    ".partitionBy(3, partitionFunc)\\\n",
    ".map(lambda x: x[0])\\\n",
    ".glom()\\\n",
    ".map(lambda x: len(set(x)))\\\n",
    ".take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14장 분산형 공유 변수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14.1 브로드캐스트 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_collection = \"Spark The Definitive Guide : Big Data Processing Made Simple\".split(' ')\n",
    "words = sc.parallelize(my_collection, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Spark': 1000, 'Definitive': 200, 'Big': -300, 'Simple': 100}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supplementalData = {\"Spark\":1000, \"Definitive\":200, \"Big\":-300, \"Simple\":100}\n",
    "\n",
    "suppBroadcast = spark.sparkContext.broadcast(supplementalData)\n",
    "suppBroadcast.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Big', -300),\n",
       " ('The', 0),\n",
       " ('Guide', 0),\n",
       " (':', 0),\n",
       " ('Data', 0),\n",
       " ('Processing', 0),\n",
       " ('Made', 0),\n",
       " ('Simple', 100),\n",
       " ('Definitive', 200),\n",
       " ('Spark', 1000)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.map(lambda word: (word, suppBroadcast.value.get(word, 0)))\\\n",
    ".sortBy(lambda wordPair: wordPair[1])\\\n",
    ".collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14.2 어큐뮬레이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 14.2.1 기본 예제\n",
    "path = \"file:///home/ubuntu/Spark-The-Definitive-Guide-master/data/flight-data/parquet/2010-summary.parquet\"\n",
    "flights = spark.read.parquet(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "accChina = sc.accumulator(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accChinaFunc(flight_row):\n",
    "    destination = flight_row['DEST_COUNTRY_NAME']\n",
    "    origin = flight_row['ORIGIN_COUNTRY_NAME']\n",
    "    \n",
    "    if destination == 'China':\n",
    "        accChina.add(flight_row['count'])\n",
    "    if origin == 'China':\n",
    "        accChina.add(flight_row['count'])\n",
    "        \n",
    "flights.foreach(lambda flight_row: accChinaFunc(flight_row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 스파크 ui 에서 확인 가능\n",
    "accChina.value"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
